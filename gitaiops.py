#!/usr/bin/env python3
"""
GitAIOps Platform - Complete AI-Powered GitLab Operations Platform
All-in-one monolithic implementation for maximum simplicity
"""
import asyncio
import json
import sys
import os
import signal
import subprocess
import time
import logging
import aiohttp
import structlog
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any, Union
from functools import lru_cache
from cachetools import TTLCache
from tenacity import retry, stop_after_attempt, wait_exponential

# FastAPI and web framework imports
from fastapi import FastAPI, Request, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
import uvicorn

# Pydantic imports
try:
    from pydantic_settings import BaseSettings
except ImportError:
    from pydantic import BaseSettings
from pydantic import Field

# WebSocket imports
import websockets
import websockets.server


# =============================================================================
# CONFIGURATION & SETTINGS
# =============================================================================

class Settings(BaseSettings):
    """Application settings with environment variable support"""
    
    # Application
    app_name: str = "GitAIOps Platform"
    app_version: str = "1.0.0"
    environment: str = Field(default="development", env="ENVIRONMENT")
    debug: bool = Field(default=True, env="DEBUG")
    
    # API Configuration
    api_host: str = Field(default="0.0.0.0", env="API_HOST")
    api_port: int = Field(default=8080, env="API_PORT")
    api_prefix: str = "/api/v1"
    
    # GitLab Configuration
    gitlab_url: str = Field(default="https://gitlab.com", env="GITLAB_URL")
    gitlab_api_url: str = Field(default="https://gitlab.com/api/v4", env="GITLAB_API_URL")
    gitlab_token: Optional[str] = Field(default="glpat-aTrQQ4EqmxGpGh3Ddcgm", env="GITLAB_TOKEN")
    gitlab_project_id: Optional[int] = Field(default=278964, env="GITLAB_PROJECT_ID")
    
    # AI Configuration - Gemini
    gemini_api_key: Optional[str] = Field(default="AIzaSyAZEcYAQ6zu9I2XRjFddmVquu44dB7dUIY", env="GEMINI_API_KEY")
    gemini_model: str = Field(default="gemini-2.0-flash", env="GEMINI_MODEL")
    
    # Neo4j Configuration
    NEO4J_URI: str = Field(default="bolt://localhost:7687", env="NEO4J_URI")
    NEO4J_USERNAME: str = Field(default="neo4j", env="NEO4J_USERNAME") 
    NEO4J_PASSWORD: str = Field(default="password", env="NEO4J_PASSWORD")
    
    # Feature flags
    enable_mr_triage: bool = Field(default=True, env="ENABLE_MR_TRIAGE")
    enable_expert_finder: bool = Field(default=True, env="ENABLE_EXPERT_FINDER")
    enable_pipeline_optimizer: bool = Field(default=True, env="ENABLE_PIPELINE_OPTIMIZER")
    enable_vulnerability_scanner: bool = Field(default=True, env="ENABLE_VULNERABILITY_SCANNER")
    enable_chatops_bot: bool = Field(default=True, env="ENABLE_CHATOPS_BOT")
    
    # Performance settings
    max_concurrent_analyses: int = Field(default=5, env="MAX_CONCURRENT_ANALYSES")
    cache_ttl_seconds: int = Field(default=3600, env="CACHE_TTL_SECONDS")
    
    # Security
    secret_key: str = Field(default="dev-secret-key", env="SECRET_KEY")
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"
        case_sensitive = False
        extra = "allow"


@lru_cache()
def get_settings() -> Settings:
    """Get cached settings instance"""
    return Settings()


# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================

structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger(__name__)


# =============================================================================
# GEMINI AI CLIENT
# =============================================================================

class GeminiClient:
    """Client for Google Gemini AI API"""
    
    def __init__(self):
        self.settings = get_settings()
        self.api_key = self.settings.gemini_api_key
        self.model = self.settings.gemini_model
        self.base_url = "https://generativelanguage.googleapis.com/v1beta"
        self.cache = TTLCache(maxsize=1000, ttl=1800)
        self.session = None
        self._init_session()
    
    def _init_session(self):
        """Initialize aiohttp session"""
        if not self.api_key:
            logger.warning("Gemini API key not configured")
            return
        
        try:
            self.session = aiohttp.ClientSession()
            logger.info("Gemini client initialized", model=self.model)
        except Exception as e:
            logger.error("Failed to initialize Gemini client", error=str(e))
    
    async def close(self):
        """Close the aiohttp session"""
        if self.session:
            await self.session.close()
    
    async def is_available(self) -> bool:
        """Check if Gemini is available"""
        return self.session is not None and self.api_key is not None
    
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
    async def generate_content(self, prompt: str, system_instruction: str = None) -> str:
        """Generate content using Gemini API"""
        if not await self.is_available():
            return "AI service temporarily unavailable. Please try again later."
        
        try:
            cache_key = f"{hash(prompt + (system_instruction or ''))}"
            if cache_key in self.cache:
                return self.cache[cache_key]
            
            url = f"{self.base_url}/models/{self.model}:generateContent?key={self.api_key}"
            
            payload = {
                "contents": [
                    {
                        "parts": [
                            {"text": prompt}
                        ]
                    }
                ]
            }
            
            if system_instruction:
                payload["systemInstruction"] = {
                    "parts": [{"text": system_instruction}]
                }
            
            async with self.session.post(url, json=payload) as response:
                if response.status == 200:
                    data = await response.json()
                    result = data["candidates"][0]["content"]["parts"][0]["text"]
                    self.cache[cache_key] = result
                    return result
                else:
                    error_text = await response.text()
                    logger.error("Gemini API error", status=response.status, error=error_text)
                    return "AI analysis temporarily unavailable."
                    
        except Exception as e:
            logger.error("Gemini request failed", error=str(e))
            return "AI analysis failed. Please try again later."


# =============================================================================
# GITLAB CLIENT
# =============================================================================

class GitLabClient:
    """GitLab API client"""
    
    def __init__(self):
        self.settings = get_settings()
        self.base_url = self.settings.gitlab_api_url
        self.token = self.settings.gitlab_token
        self.session = None
        self._init_session()
    
    def _init_session(self):
        """Initialize aiohttp session"""
        if not self.token:
            logger.warning("GitLab token not configured")
            return
            
        headers = {
            "Private-Token": self.token,
            "Content-Type": "application/json"
        }
        
        try:
            self.session = aiohttp.ClientSession(headers=headers)
            logger.info("GitLab client initialized")
        except Exception as e:
            logger.error("Failed to initialize GitLab client", error=str(e))
    
    async def close(self):
        """Close the aiohttp session"""
        if self.session:
            await self.session.close()
    
    async def is_available(self) -> bool:
        """Check if GitLab is available"""
        if not self.session:
            return False
        try:
            async with self.session.get(f"{self.base_url}/user") as response:
                return response.status == 200
        except:
            return False
    
    async def get_project(self, project_id: int) -> Optional[Dict]:
        """Get project information"""
        if not self.session:
            return None
        try:
            async with self.session.get(f"{self.base_url}/projects/{project_id}") as response:
                if response.status == 200:
                    return await response.json()
        except Exception as e:
            logger.error("Failed to get project", project_id=project_id, error=str(e))
        return None
    
    async def get_merge_request(self, project_id: int, mr_iid: int) -> Optional[Dict]:
        """Get merge request information"""
        if not self.session:
            return None
        try:
            url = f"{self.base_url}/projects/{project_id}/merge_requests/{mr_iid}"
            async with self.session.get(url) as response:
                if response.status == 200:
                    return await response.json()
        except Exception as e:
            logger.error("Failed to get merge request", project_id=project_id, mr_iid=mr_iid, error=str(e))
        return None


# =============================================================================
# AI FEATURES
# =============================================================================

class MRTriageSystem:
    """AI-powered merge request triage system"""
    
    def __init__(self, gitlab_client: GitLabClient, gemini_client: GeminiClient):
        self.gitlab_client = gitlab_client
        self.gemini_client = gemini_client
        self.cache = TTLCache(maxsize=500, ttl=3600)
    
    async def analyze_merge_request(self, project_id: int, mr_iid: int) -> Dict[str, Any]:
        """Analyze a merge request using AI"""
        cache_key = f"{project_id}:{mr_iid}"
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        try:
            # Get MR data
            mr_data = await self.gitlab_client.get_merge_request(project_id, mr_iid)
            if not mr_data:
                return {"error": "Merge request not found"}
            
            # Generate AI analysis
            prompt = f"""
            Analyze this merge request:
            Title: {mr_data.get('title', '')}
            Description: {mr_data.get('description', '')}
            Author: {mr_data.get('author', {}).get('name', '')}
            Source Branch: {mr_data.get('source_branch', '')}
            Target Branch: {mr_data.get('target_branch', '')}
            
            Provide a brief analysis covering:
            1. Risk level (Low/Medium/High)
            2. Key changes summary
            3. Recommendations
            """
            
            analysis = await self.gemini_client.generate_content(prompt)
            
            result = {
                "mr_iid": mr_iid,
                "project_id": project_id,
                "title": mr_data.get('title'),
                "author": mr_data.get('author', {}).get('name'),
                "ai_analysis": analysis,
                "analyzed_at": datetime.now().isoformat()
            }
            
            self.cache[cache_key] = result
            return result
            
        except Exception as e:
            logger.error("MR analysis failed", error=str(e), mr_iid=mr_iid, project_id=project_id)
            return {"error": f"Analysis failed: {str(e)}"}


class ChatOpsBot:
    """AI-powered ChatOps bot"""
    
    def __init__(self, gitlab_client: GitLabClient, gemini_client: GeminiClient):
        self.gitlab_client = gitlab_client
        self.gemini_client = gemini_client
    
    async def process_chat_request(self, message: str, project_id: int) -> str:
        """Process a chat request and generate AI response"""
        try:
            system_instruction = """
            You are a GitLab DevOps assistant. Help users with:
            - Code review insights
            - Pipeline troubleshooting
            - GitLab best practices
            - Project analysis
            Keep responses concise and actionable.
            """
            
            prompt = f"User question about project {project_id}: {message}"
            response = await self.gemini_client.generate_content(prompt, system_instruction)
            return response
            
        except Exception as e:
            logger.error("Chat request failed", error=str(e))
            return "I'm experiencing technical difficulties. Please try again later."


# =============================================================================
# SERVICE REGISTRY
# =============================================================================

class ServiceRegistry:
    """Centralized service registry and health monitoring"""
    
    def __init__(self):
        self.services = {}
        self.health_checks = {}
    
    def register_service(self, name: str, service: Any, health_check: callable = None):
        """Register a service"""
        self.services[name] = service
        if health_check:
            self.health_checks[name] = health_check
        logger.info("Service registered", service=name)
    
    async def get_health_status(self) -> Dict[str, Any]:
        """Get health status of all services"""
        status = {}
        for name, service in self.services.items():
            try:
                if name in self.health_checks:
                    is_healthy = await self.health_checks[name]()
                elif hasattr(service, 'is_available'):
                    is_healthy = await service.is_available()
                else:
                    is_healthy = True
                
                status[name] = {
                    "status": "healthy" if is_healthy else "unhealthy",
                    "last_check": datetime.now().isoformat(),
                    "error_count": 0
                }
            except Exception as e:
                status[name] = {
                    "status": "error",
                    "last_check": datetime.now().isoformat(),
                    "error": str(e),
                    "error_count": 1
                }
        
        return status


# =============================================================================
# WEBSOCKET SERVERS
# =============================================================================

class WebSocketManager:
    """Unified WebSocket management"""
    
    def __init__(self):
        self.clients = {
            "events": set(),
            "dashboard": set(),
            "testing": set()
        }
        self.servers = {}
    
    async def start_servers(self):
        """Start all WebSocket servers"""
        try:
            # Events WebSocket
            self.servers["events"] = await websockets.serve(
                self.handle_events_ws, "localhost", 8766
            )
            logger.info("Events WebSocket started on port 8766")
            
            # Dashboard WebSocket
            self.servers["dashboard"] = await websockets.serve(
                self.handle_dashboard_ws, "localhost", 8767
            )
            logger.info("Dashboard WebSocket started on port 8767")
            
            # Testing WebSocket
            self.servers["testing"] = await websockets.serve(
                self.handle_testing_ws, "localhost", 8765
            )
            logger.info("Testing WebSocket started on port 8765")
            
        except Exception as e:
            logger.error("Failed to start WebSocket servers", error=str(e))
    
    async def handle_events_ws(self, websocket, path):
        """Handle events WebSocket connections"""
        self.clients["events"].add(websocket)
        try:
            await websocket.send(json.dumps({
                "type": "welcome",
                "message": "Connected to Events WebSocket"
            }))
            async for message in websocket:
                # Echo to all clients
                await self.broadcast("events", message)
        except websockets.exceptions.ConnectionClosed:
            pass
        finally:
            self.clients["events"].remove(websocket)
    
    async def handle_dashboard_ws(self, websocket, path):
        """Handle dashboard WebSocket connections"""
        self.clients["dashboard"].add(websocket)
        try:
            await websocket.send(json.dumps({
                "type": "welcome",
                "message": "Connected to Dashboard WebSocket"
            }))
            async for message in websocket:
                await self.broadcast("dashboard", message)
        except websockets.exceptions.ConnectionClosed:
            pass
        finally:
            self.clients["dashboard"].remove(websocket)
    
    async def handle_testing_ws(self, websocket, path):
        """Handle testing WebSocket connections"""
        self.clients["testing"].add(websocket)
        try:
            await websocket.send(json.dumps({
                "type": "welcome",
                "message": "Connected to Testing WebSocket"
            }))
            async for message in websocket:
                data = json.loads(message)
                response = {
                    "type": "echo",
                    "data": data,
                    "timestamp": datetime.now().isoformat()
                }
                await self.broadcast("testing", json.dumps(response))
        except websockets.exceptions.ConnectionClosed:
            pass
        finally:
            self.clients["testing"].remove(websocket)
    
    async def broadcast(self, server_type: str, message: str):
        """Broadcast message to all clients of a server type"""
        if self.clients[server_type]:
            await asyncio.gather(
                *[client.send(message) for client in self.clients[server_type]],
                return_exceptions=True
            )


# =============================================================================
# FASTAPI APPLICATION
# =============================================================================

def create_app() -> FastAPI:
    """Create and configure FastAPI application"""
    settings = get_settings()
    
    app = FastAPI(
        title="GitAIOps Platform",
        description="AI-powered DevOps platform for GitLab integration",
        version="1.0.0",
        docs_url="/docs",
        redoc_url="/redoc"
    )
    
    # CORS middleware
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
    
    # Initialize clients
    gitlab_client = GitLabClient()
    gemini_client = GeminiClient()
    
    # Initialize features
    mr_triage = MRTriageSystem(gitlab_client, gemini_client)
    chatops_bot = ChatOpsBot(gitlab_client, gemini_client)
    
    # Initialize service registry
    service_registry = ServiceRegistry()
    service_registry.register_service("gitlab_client", gitlab_client)
    service_registry.register_service("gemini_client", gemini_client)
    service_registry.register_service("mr_triage", mr_triage)
    service_registry.register_service("chatops_bot", chatops_bot)
    
    # Store in app state
    app.state.gitlab_client = gitlab_client
    app.state.gemini_client = gemini_client
    app.state.mr_triage = mr_triage
    app.state.chatops_bot = chatops_bot
    app.state.service_registry = service_registry
    
    # Serve React dashboard
    dashboard_path = Path(__file__).parent / "dashboard" / "build"
    if dashboard_path.exists():
        app.mount("/static", StaticFiles(directory=str(dashboard_path / "static")), name="static")
    
    # =============================================================================
    # API ROUTES
    # =============================================================================
    
    @app.get("/")
    async def root():
        """Root endpoint"""
        return {
            "message": "GitAIOps Platform API",
            "version": "1.0.0",
            "docs": "/docs",
            "health": "/health",
            "dashboard": "/dashboard"
        }
    
    @app.get("/health")
    async def health_check():
        """Health check endpoint"""
        health_status = await service_registry.get_health_status()
        healthy_count = sum(1 for s in health_status.values() if s["status"] == "healthy")
        
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "service": "gitaiops-platform",
            "services": health_status,
            "healthy_services": healthy_count,
            "total_services": len(health_status)
        }
    
    @app.get("/dashboard")
    async def dashboard():
        """Serve React dashboard"""
        dashboard_file = dashboard_path / "index.html"
        if dashboard_file.exists():
            return FileResponse(str(dashboard_file))
        else:
            raise HTTPException(status_code=404, detail="Dashboard not built")
    
    @app.get("/dashboard/{path:path}")
    async def dashboard_spa(path: str):
        """Serve React app for all dashboard routes"""
        dashboard_file = dashboard_path / "index.html"
        if dashboard_file.exists():
            return FileResponse(str(dashboard_file))
        else:
            raise HTTPException(status_code=404, detail="Dashboard not built")
    
    # GitLab API routes
    @app.get("/api/v1/gitlab/projects/{project_id}")
    async def get_project(project_id: int):
        """Get GitLab project information"""
        project = await gitlab_client.get_project(project_id)
        if project:
            return project
        else:
            raise HTTPException(status_code=404, detail="Project not found")
    
    # AI feature routes
    @app.get("/api/v1/ai/triage/demo")
    async def demo_mr_triage(project_id: int = None):
        """Demo MR triage analysis"""
        demo_data = {
            "demo": True,
            "project_name": "ecommerce-platform",
            "project_id": project_id or 278964,
            "mr_iid": 1247,
            "mr_title": "Add Redis caching for product queries",
            "author": "alice.developer",
            "ai_analysis": """**Risk Level:** Medium

**Key Changes Summary:**
- Implements Redis caching layer for product database queries
- Adds cache invalidation logic for product updates
- Includes new Redis configuration and connection pooling

**Recommendations:**
1. ‚úÖ Code quality looks good with proper error handling
2. ‚ö†Ô∏è Consider adding cache TTL configuration for different product types
3. üîç Verify cache invalidation covers all product update scenarios
4. üìä Monitor cache hit ratios post-deployment

**Overall Assessment:** Well-structured implementation that should improve query performance. Ready for testing phase.""",
            "analyzed_at": datetime.now().isoformat()
        }
        return demo_data
    
    @app.get("/api/v1/ai/chat/demo")
    async def demo_ai_chat(project_id: int = None):
        """Demo AI chat responses"""
        demo_responses = [
            {
                "input": "Why did build #1247 fail?",
                "response": "Build #1247 failed in the 'integration-tests' stage due to a test timeout. The Redis connection test exceeded the 30-second limit, likely due to network latency. Consider increasing the timeout or checking Redis connectivity."
            },
            {
                "input": "What's the code coverage for the latest commit?",
                "response": "The latest commit has 87.3% code coverage. This is above the project threshold of 85%. The uncovered lines are mainly in error handling paths and configuration modules."
            },
            {
                "input": "Should we merge MR !456?",
                "response": "MR !456 looks ready for merge. It has: ‚úÖ All tests passing, ‚úÖ Code coverage maintained, ‚úÖ 2 approvals, ‚úÖ No merge conflicts. The performance improvements in the authentication module are well-tested."
            }
        ]
        
        return {
            "demo": True,
            "project_name": "web-app-backend",
            "responses": demo_responses
        }
    
    @app.get("/api/v1/metrics/events")
    async def get_metrics():
        """Get platform metrics"""
        return {
            "events_processed": 1247,
            "active_projects": 23,
            "ai_analyses_today": 156,
            "system_uptime": "2d 14h 23m",
            "last_updated": datetime.now().isoformat()
        }
    
    # Startup and shutdown events
    @app.on_event("startup")
    async def startup_event():
        logger.info("GitAIOps Platform starting up")
        # Initialize WebSocket manager
        app.state.websocket_manager = WebSocketManager()
        await app.state.websocket_manager.start_servers()
    
    @app.on_event("shutdown")
    async def shutdown_event():
        logger.info("GitAIOps Platform shutting down")
        await gitlab_client.close()
        await gemini_client.close()
    
    return app


# =============================================================================
# UNIFIED SYSTEM LAUNCHER
# =============================================================================

class UnifiedLauncher:
    """Unified system launcher for all components"""
    
    def __init__(self):
        self.processes = {}
        self.running = False
        self.app = None
    
    async def start_system(self, host="localhost", port=8000):
        """Start the complete GitAIOps system"""
        logger.info("üöÄ Starting GitAIOps Platform")
        
        try:
            # Create FastAPI app
            self.app = create_app()
            
            # Start API server
            config = uvicorn.Config(
                app=self.app,
                host=host,
                port=port,
                log_level="info"
            )
            server = uvicorn.Server(config)
            
            # Start React development server in background
            await self.start_react_dev_server()
            
            logger.info("‚úÖ GitAIOps Platform started successfully!")
            logger.info(f"üåê Dashboard: http://{host}:{port}/dashboard")
            logger.info(f"üìö API Docs: http://{host}:{port}/docs")
            logger.info(f"üí¨ AI Chat: http://{host}:{port}/api/v1/ai/chat/demo")
            
            # Run server
            await server.serve()
            
        except Exception as e:
            logger.error("Failed to start system", error=str(e))
            raise
    
    async def start_react_dev_server(self):
        """Start React development server"""
        dashboard_path = Path(__file__).parent / "dashboard"
        if (dashboard_path / "package.json").exists():
            try:
                # Check if build exists, if not try to create it
                build_path = dashboard_path / "build"
                if not build_path.exists():
                    logger.info("Building React dashboard...")
                    subprocess.run(
                        ["npm", "run", "build"],
                        cwd=dashboard_path,
                        check=True,
                        capture_output=True
                    )
                    logger.info("‚úÖ React dashboard built")
                
                # Start dev server in background
                self.processes["react"] = subprocess.Popen(
                    ["npm", "start"],
                    cwd=dashboard_path,
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.DEVNULL
                )
                logger.info("‚úÖ React dev server started on port 3000")
                
            except Exception as e:
                logger.warning("Failed to start React dev server", error=str(e))
    
    def stop_system(self):
        """Stop all system components"""
        logger.info("üõë Stopping GitAIOps Platform...")
        
        for name, process in self.processes.items():
            try:
                process.terminate()
                logger.info(f"Stopped {name}")
            except Exception as e:
                logger.error(f"Error stopping {name}", error=str(e))
        
        self.running = False
        logger.info("‚úÖ GitAIOps Platform stopped")


# =============================================================================
# MAIN ENTRY POINT
# =============================================================================

async def main():
    """Main entry point"""
    launcher = UnifiedLauncher()
    
    # Setup signal handlers
    def signal_handler(signum, frame):
        launcher.stop_system()
        sys.exit(0)
    
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    try:
        await launcher.start_system()
    except KeyboardInterrupt:
        launcher.stop_system()
    except Exception as e:
        logger.error("Fatal error", error=str(e))
        sys.exit(1)


if __name__ == "__main__":
    print("üåü GitAIOps Platform - Complete AI-Powered GitLab Operations")
    print("=" * 60)
    asyncio.run(main())