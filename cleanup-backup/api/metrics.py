"""
Real-time Metrics API Routes

RESTful API for real-time metrics, anomaly detection, and performance monitoring.
"""

from fastapi import APIRouter, HTTPException, Query, Depends
from pydantic import BaseModel, Field
from typing import Dict, List, Optional, Any
from datetime import datetime
import structlog

from src.features.realtime_metrics import (
    get_metrics_system,
    MetricType,
    AlertSeverity,
    TrendAnalysis
)

logger = structlog.get_logger(__name__)

router = APIRouter()

# Response Models
class MetricsSummaryResponse(BaseModel):
    """Metrics summary response"""
    timeframe_hours: int
    metrics: Dict[str, Any]
    alerts_count: int
    anomalies_count: int

class AlertResponse(BaseModel):
    """Performance alert response"""
    id: str
    severity: str
    title: str
    description: str
    metric_type: str
    threshold_breached: float
    current_value: float
    project_id: Optional[int]
    timestamp: str
    suggested_actions: List[str]
    auto_resolved: bool

class TrendAnalysisResponse(BaseModel):
    """Trend analysis response"""
    metric_type: str
    trend_direction: str
    change_rate: float
    confidence: float
    time_period_days: int
    key_insights: List[str]

class SystemStatsResponse(BaseModel):
    """System statistics response"""
    monitoring_active: bool
    total_metrics_collected: int
    metric_types_count: int
    total_anomalies: int
    total_alerts: int
    collection_interval_seconds: int
    latest_collection: Optional[str]
    buffer_sizes: Dict[str, int]

# Routes
@router.get("/summary", response_model=MetricsSummaryResponse)
async def get_metrics_summary(
    project_id: Optional[int] = Query(None, description="Filter by project ID"),
    hours: int = Query(24, ge=1, le=168, description="Time window in hours (max 7 days)")
):
    """
    Get metrics summary for dashboard
    
    Returns aggregated metrics for the specified time period, including:
    - Pipeline performance metrics
    - Build and deployment frequency
    - Quality metrics
    - Alert and anomaly counts
    """
    
    try:
        metrics_system = await get_metrics_system()
        summary = await metrics_system.get_metrics_summary(
            project_id=project_id,
            hours=hours
        )
        
        return MetricsSummaryResponse(**summary)
        
    except Exception as e:
        logger.error(
            "Metrics summary retrieval failed",
            project_id=project_id,
            hours=hours,
            error=str(e)
        )
        raise HTTPException(
            status_code=500,
            detail=f"Failed to get metrics summary: {str(e)}"
        )

@router.get("/alerts", response_model=List[AlertResponse])
async def get_recent_alerts(
    limit: int = Query(20, ge=1, le=100, description="Maximum number of alerts"),
    severity: Optional[str] = Query(None, description="Filter by severity")
):
    """
    Get recent performance alerts
    
    Returns list of recent alerts generated by the anomaly detection system,
    ordered by timestamp (newest first).
    """
    
    try:
        # Validate severity if provided
        severity_filter = None
        if severity:
            try:
                severity_filter = AlertSeverity(severity.lower())
            except ValueError:
                raise HTTPException(
                    status_code=400,
                    detail=f"Invalid severity '{severity}'. Must be one of: low, medium, high, critical"
                )
        
        metrics_system = await get_metrics_system()
        alerts = await metrics_system.get_recent_alerts(
            limit=limit,
            severity=severity_filter
        )
        
        return [AlertResponse(**alert) for alert in alerts]
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(
            "Alerts retrieval failed",
            limit=limit,
            severity=severity,
            error=str(e)
        )
        raise HTTPException(
            status_code=500,
            detail=f"Failed to get alerts: {str(e)}"
        )

@router.get("/trends/{metric_type}", response_model=TrendAnalysisResponse)
async def get_trend_analysis(
    metric_type: str,
    days: int = Query(7, ge=1, le=30, description="Time period in days"),
    project_id: Optional[int] = Query(None, description="Filter by project ID")
):
    """
    Get trend analysis for a specific metric
    
    Analyzes historical data to identify trends, calculate change rates,
    and provide insights about metric behavior over time.
    """
    
    try:
        # Validate metric type
        try:
            metric_enum = MetricType(metric_type.lower())
        except ValueError:
            valid_metrics = [m.value for m in MetricType]
            raise HTTPException(
                status_code=400,
                detail=f"Invalid metric type '{metric_type}'. Must be one of: {', '.join(valid_metrics)}"
            )
        
        metrics_system = await get_metrics_system()
        trend_analysis = await metrics_system.get_trend_analysis(
            metric_type=metric_enum,
            days=days,
            project_id=project_id
        )
        
        return TrendAnalysisResponse(
            metric_type=trend_analysis.metric_type.value,
            trend_direction=trend_analysis.trend_direction,
            change_rate=trend_analysis.change_rate,
            confidence=trend_analysis.confidence,
            time_period_days=trend_analysis.time_period_days,
            key_insights=trend_analysis.key_insights
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(
            "Trend analysis failed",
            metric_type=metric_type,
            days=days,
            project_id=project_id,
            error=str(e)
        )
        raise HTTPException(
            status_code=500,
            detail=f"Failed to get trend analysis: {str(e)}"
        )

@router.get("/system/stats", response_model=SystemStatsResponse)
async def get_system_stats():
    """
    Get real-time metrics system statistics
    
    Returns information about the monitoring system status,
    data collection statistics, and buffer utilization.
    """
    
    try:
        metrics_system = await get_metrics_system()
        stats = await metrics_system.get_system_stats()
        
        # Convert datetime to string if present
        if stats.get("latest_collection"):
            stats["latest_collection"] = stats["latest_collection"].isoformat()
        
        return SystemStatsResponse(**stats)
        
    except Exception as e:
        logger.error("System stats retrieval failed", error=str(e))
        raise HTTPException(
            status_code=500,
            detail=f"Failed to get system stats: {str(e)}"
        )

@router.get("/types")
async def get_metric_types():
    """
    Get available metric types
    
    Returns list of all metric types that are being monitored
    by the real-time metrics system.
    """
    
    return {
        "metric_types": [
            {
                "name": metric_type.value,
                "display_name": metric_type.value.replace("_", " ").title(),
                "description": _get_metric_description(metric_type)
            }
            for metric_type in MetricType
        ]
    }

@router.get("/demo")
async def demo_metrics():
    """
    Demo metrics endpoint
    
    Provides sample metrics data for demonstration purposes,
    showing the types of insights available from the monitoring system.
    """
    
    try:
        metrics_system = await get_metrics_system()
        
        # Get actual summary if available
        summary = await metrics_system.get_metrics_summary(hours=24)
        
        # Get recent alerts
        alerts = await metrics_system.get_recent_alerts(limit=5)
        
        return {
            "demo": True,
            "message": "Real-time metrics monitoring system",
            "features": [
                "Pipeline duration monitoring",
                "Success rate tracking", 
                "Anomaly detection",
                "Performance alerts",
                "Trend analysis"
            ],
            "current_summary": summary,
            "sample_alerts": alerts[:3],  # Show first 3 alerts
            "supported_metrics": [m.value for m in MetricType],
            "monitoring_active": summary.get("monitoring_active", False)
        }
        
    except Exception as e:
        logger.error("Demo metrics failed", error=str(e))
        
        # Return fallback demo data
        return {
            "demo": True,
            "message": "Real-time metrics monitoring system",
            "status": "fallback",
            "features": [
                "Pipeline duration monitoring",
                "Success rate tracking", 
                "Anomaly detection",
                "Performance alerts",
                "Trend analysis"
            ],
            "sample_metrics": {
                "pipeline_duration": {
                    "latest_value": 12.5,
                    "avg_value": 10.2,
                    "trend": "increasing"
                },
                "pipeline_success_rate": {
                    "latest_value": 0.92,
                    "avg_value": 0.95,
                    "trend": "decreasing"
                },
                "vulnerability_count": {
                    "latest_value": 3,
                    "avg_value": 2.1,
                    "trend": "increasing"
                }
            },
            "sample_alerts": [
                {
                    "id": "pipeline_duration_alert_001",
                    "severity": "medium",
                    "title": "Pipeline Duration Anomaly",
                    "description": "Pipeline duration increased by 25%",
                    "metric_type": "pipeline_duration",
                    "current_value": 15.2,
                    "threshold_breached": 12.0,
                    "timestamp": datetime.utcnow().isoformat(),
                    "suggested_actions": [
                        "Review recent pipeline changes",
                        "Check for resource contention"
                    ]
                }
            ],
            "supported_metrics": [m.value for m in MetricType],
            "monitoring_active": False
        }

@router.post("/system/start")
async def start_monitoring():
    """
    Start real-time monitoring
    
    Starts the background processes for metrics collection
    and anomaly detection.
    """
    
    try:
        metrics_system = await get_metrics_system()
        await metrics_system.start_monitoring()
        
        return {
            "status": "started",
            "message": "Real-time monitoring started successfully"
        }
        
    except Exception as e:
        logger.error("Failed to start monitoring", error=str(e))
        raise HTTPException(
            status_code=500,
            detail=f"Failed to start monitoring: {str(e)}"
        )

@router.post("/system/stop")
async def stop_monitoring():
    """
    Stop real-time monitoring
    
    Stops the background processes for metrics collection
    and anomaly detection.
    """
    
    try:
        metrics_system = await get_metrics_system()
        await metrics_system.stop_monitoring()
        
        return {
            "status": "stopped",
            "message": "Real-time monitoring stopped successfully"
        }
        
    except Exception as e:
        logger.error("Failed to stop monitoring", error=str(e))
        raise HTTPException(
            status_code=500,
            detail=f"Failed to stop monitoring: {str(e)}"
        )

# Helper Functions
def _get_metric_description(metric_type: MetricType) -> str:
    """Get description for metric type"""
    
    descriptions = {
        MetricType.PIPELINE_DURATION: "Time taken for CI/CD pipelines to complete",
        MetricType.PIPELINE_SUCCESS_RATE: "Percentage of successful pipeline runs",
        MetricType.BUILD_FREQUENCY: "Number of builds per day",
        MetricType.DEPLOYMENT_FREQUENCY: "Number of deployments per day",
        MetricType.MR_CYCLE_TIME: "Time from MR creation to merge",
        MetricType.CODE_QUALITY_SCORE: "Overall code quality assessment",
        MetricType.VULNERABILITY_COUNT: "Number of security vulnerabilities detected",
        MetricType.TEST_COVERAGE: "Percentage of code covered by tests"
    }
    
    return descriptions.get(
        metric_type,
        f"Monitoring metric: {metric_type.value}"
    )